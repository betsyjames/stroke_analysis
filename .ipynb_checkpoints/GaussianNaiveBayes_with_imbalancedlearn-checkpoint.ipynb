{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tabpy_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>18234</td>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>44873</td>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>19723</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>37544</td>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>44679</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "5105  18234  Female  80.0             1              0          Yes   \n",
       "5106  44873  Female  81.0             0              0          Yes   \n",
       "5107  19723  Female  35.0             0              0          Yes   \n",
       "5108  37544    Male  51.0             0              0          Yes   \n",
       "5109  44679  Female  44.0             0              0          Yes   \n",
       "\n",
       "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "5105        Private          Urban              83.75   NaN     never smoked   \n",
       "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
       "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
       "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
       "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
       "\n",
       "      stroke  \n",
       "5105       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the original Kaggle CSV\n",
    "stroke_df_initial = pd.read_csv(os.path.join('Resources/healthcare-dataset-stroke-data.csv'))\n",
    "stroke_df_initial.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0       Male  67.0             0              1          Yes        Private   \n",
       "1     Female  61.0             0              0          Yes  Self-employed   \n",
       "2       Male  80.0             0              1          Yes        Private   \n",
       "3     Female  49.0             0              0          Yes        Private   \n",
       "4     Female  79.0             1              0          Yes  Self-employed   \n",
       "...      ...   ...           ...            ...          ...            ...   \n",
       "5105  Female  80.0             1              0          Yes        Private   \n",
       "5106  Female  81.0             0              0          Yes  Self-employed   \n",
       "5107  Female  35.0             0              0          Yes  Self-employed   \n",
       "5108    Male  51.0             0              0          Yes        Private   \n",
       "5109  Female  44.0             0              0          Yes       Govt_job   \n",
       "\n",
       "     Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0             Urban             228.69  36.6  formerly smoked       1  \n",
       "1             Rural             202.21   NaN     never smoked       1  \n",
       "2             Rural             105.92  32.5     never smoked       1  \n",
       "3             Urban             171.23  34.4           smokes       1  \n",
       "4             Rural             174.12  24.0     never smoked       1  \n",
       "...             ...                ...   ...              ...     ...  \n",
       "5105          Urban              83.75   NaN     never smoked       0  \n",
       "5106          Urban             125.20  40.0     never smoked       0  \n",
       "5107          Rural              82.99  30.6     never smoked       0  \n",
       "5108          Rural             166.29  25.6  formerly smoked       0  \n",
       "5109          Urban              85.28  26.2          Unknown       0  \n",
       "\n",
       "[5110 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ID column is not necessary. Drop\n",
    "stroke_df = stroke_df_initial.drop(['id'], axis = 1)\n",
    "stroke_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "Residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  201\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for nulls\n",
    "print(stroke_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "201 rows of NA for bmi column only. Consider Drop NA but do complete data exploration first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5110 non-null   object \n",
      " 1   age                5110 non-null   float64\n",
      " 2   hypertension       5110 non-null   int64  \n",
      " 3   heart_disease      5110 non-null   int64  \n",
      " 4   ever_married       5110 non-null   object \n",
      " 5   work_type          5110 non-null   object \n",
      " 6   Residence_type     5110 non-null   object \n",
      " 7   avg_glucose_level  5110 non-null   float64\n",
      " 8   bmi                4909 non-null   float64\n",
      " 9   smoking_status     5110 non-null   object \n",
      " 10  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 439.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking number of entries, data types\n",
    "stroke_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4612\n",
       "1     498\n",
       "Name: hypertension, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts for hypertension column to ensure only two choices\n",
    "stroke_df[\"hypertension\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4834\n",
       "1     276\n",
       "Name: heart_disease, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts for heart diseease column to ensure only two choices\n",
    "stroke_df[\"heart_disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4861\n",
       "1     249\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts for stroke column to ensure only two choices\n",
    "stroke_df[\"stroke\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only 249 patients with stroke. How many will we lose if we Drop NA for the bmi column?\n",
    "bmi_null_stroke = stroke_df.loc[(stroke_df['bmi'].isna() == True) & (stroke_df['stroke'] == 1)]\n",
    "len(bmi_null_stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 is too many rows of valuable data to lose here. Consider other options. Insert mean into BMI? Other ideas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rename() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f0912da814c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mstroke_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'column'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'counts'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'column'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'counts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# stroke_df[counts].melt(var_name='column', value_name='value')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: rename() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "#Check the value counts of all columns with datatype 'object' for a guide to encoding needs\n",
    "#Check the value counts of all columns with datatype 'object' for a guide to encoding needs\n",
    "counts = stroke_df.select_dtypes(include=object).columns.tolist()\n",
    "(pd.DataFrame(\n",
    "    stroke_df[counts]\n",
    "    .melt(var_name='column', value_name='value')\n",
    "    .value_counts())\n",
    ".rename(columns={0: 'counts'})\n",
    ".sort_values(by=['column', 'counts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that gender only has one 'other'; probably easier to remove that point for binary encoding. Note that one of the work_types is \"children,\" meaning the dataset includes children. Look at age more closely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examining age column\n",
    "stroke_df.sort_values(by=['age']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset even contains babies. Children are likely less useful in predicting stroke, although these particular children may have some other health issues, which is why they were included. How many children actually are labeled with stroke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Children stroke count\n",
    "children_stroke = stroke_df.loc[(stroke_df['age'] < 17) & (stroke_df['stroke'] == 1)]\n",
    "len(children_stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove children from the dataset in this instance and compare model performance with the children data left in vs deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing children from the dataset\n",
    "\n",
    "no_children_df = stroke_df[stroke_df.age > 16]\n",
    "no_children_df.sort_values(by=['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure children is no longer listed as a work type\n",
    "no_children_df.sort_values(by=['age'])\n",
    "no_children_df['work_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the 'other' row in gender column\n",
    "cleaned_stroke_df = no_children_df[no_children_df.gender != 'Other']\n",
    "cleaned_stroke_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas get_dummies to convert categorical data\n",
    "\n",
    "encoded_df = pd.get_dummies(cleaned_stroke_df, columns=['gender','ever_married', 'Residence_type'])\n",
    "encoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the extra dummies columns\n",
    "encoded_stroke_df = encoded_df.drop(columns=['gender_Female','ever_married_No','Residence_type_Rural'])\n",
    "encoded_stroke_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode the categorical columns that have more than two choices\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "encoded_stroke_df['work_type']= label_encoder.fit_transform(encoded_stroke_df['work_type']) \n",
    "encoded_stroke_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "encoded_stroke_df['smoking_status']= label_encoder.fit_transform(encoded_stroke_df['smoking_status']) \n",
    "encoded_stroke_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of bmi column to view outliers\n",
    "encoded_stroke_df.hist(column = 'bmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by bmi to see highest values\n",
    "encoded_stroke_df.sort_values(by=['bmi'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine bmi outliers using upper and lower bounds\n",
    "quartiles = encoded_stroke_df['bmi'].quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "outliers = encoded_stroke_df.loc[(encoded_stroke_df['bmi'] < lower_bound) | (encoded_stroke_df['bmi'] > upper_bound)]\n",
    "        \n",
    "#Display upper & lower bounds and number of outliers\n",
    "       \n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick look at the data\n",
    "encoded_stroke_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the median values to compare mean and median in bmi\n",
    "encoded_stroke_df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and median are nearly identical. Either is an acceptable replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set mean to a variable\n",
    "mean_bmi = encoded_stroke_df['bmi'].mean()\n",
    "mean_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN with mean bmi\n",
    "replace_stroke_df = encoded_stroke_df.fillna(mean_bmi)\n",
    "replace_stroke_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a correlation heatmap of all of the features\n",
    "correlation = replace_stroke_df.corr()\n",
    "plt.figure (figsize = (10,8))\n",
    "sns.heatmap(correlation, annot = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marital status had a small correlation with age. Age makes more sense to keep in the features for a medical model, so try removing ever_married to see the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove ever_married column and then train/test the model to see if it helps performance.\n",
    "final_stroke_df = replace_stroke_df.drop(['ever_married_Yes'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the ever_married column does not make improvement to the model. Actually the F1 and precision drop one-tenth. Keep the ever_married column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model work starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = replace_stroke_df.drop([\"stroke\"], axis=1)\n",
    "y = replace_stroke_df[\"stroke\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the distribution of stroke/no stroke in the test data\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian Naive Bayes model is not likely to be very affected by feature scaling, especially given the small dataset and the fact that it weights features accordingly by design, but try a standard scaler and see if it affects the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "\n",
    "# Transform the training and testing data using the X_scaler model. Y is the target so we don't scale the y.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performance is exactly the same with scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model (Gaussian Naive Bayes)\n",
    "nbclf = GaussianNB()\n",
    "\n",
    "#Fit (train) model using the training data\n",
    "nbclf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try cross validation and calculate accuracy score as well as AUC ROC score for 10-fold\n",
    "scores = cross_val_score(nbclf, X_test, y_test, cv=10, scoring='roc_auc')\n",
    "\n",
    "# Show accuracy statistics for cross-validation\n",
    "\n",
    "print(\"Accuracy: %0.3f\" % (scores.mean()))\n",
    "print(\"Aucroc: %0.3f\" % metrics.roc_auc_score(y_test, cross_val_predict(nbclf, X_test, y_test, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try KFold cross validation\n",
    "\n",
    "kfold = KFold(n_splits= 10, shuffle = True, random_state = 42)\n",
    "result = result = cross_val_score(nbclf, X_test, y_test, cv=kfold, scoring='accuracy')\n",
    "print(\"Accuracy: %0.3f\" % (result.mean()))\n",
    "print(\"Aucroc: %0.3f\" % metrics.roc_auc_score(y_test, cross_val_predict(nbclf, X_test, y_test, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy does not improve with Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for original test/train split\n",
    "predictions = nbclf.predict(X_test)\n",
    "sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix to see correct and incorrect predictions for original test/train split\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute precision, recall F1-score and support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an informative confusion matrix using seaborn\n",
    "\n",
    "#Define variables for Information inside each box\n",
    "category = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "counts = ['{0:0.0f}'.format(value) for value in confusion_matrix.flatten()]\n",
    "percentages = ['{0:.1%}'.format(value) for value in confusion_matrix.flatten()/np.sum(confusion_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(category, counts, percentages)]\n",
    "\n",
    "#Convert all of the labels to an array and reshape\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "#Change the 0,1 to no stroke and stroke for labels\n",
    "tick_labels = ['No Stroke', 'Stroke']\n",
    "\n",
    "#Calculate all of the values to be displayed underneath the matrix as xlabel. Calculate precision, recall, F1 for both\n",
    "#stroke and no stroke\n",
    "accuracy  = np.trace(confusion_matrix) / float(np.sum(confusion_matrix))\n",
    "precision_stroke = confusion_matrix[1,1] / sum(confusion_matrix[:,1])\n",
    "recall_stroke    = confusion_matrix[1,1] / sum(confusion_matrix[1,:])\n",
    "f1_score_stroke  = 2*precision_stroke*recall_stroke / (precision_stroke + recall_stroke)\n",
    "precision = confusion_matrix[0,0] / sum(confusion_matrix[:,0])\n",
    "recall    = confusion_matrix[0,0] / sum(confusion_matrix[0,:])\n",
    "f1_score  = 2*precision*recall / (precision + recall)\n",
    "\n",
    "#Set up the text for the x label display underneath the matrix\n",
    "stats_text = \"\\n\\nAccuracy={:0.2f}\\nPrecision (stroke)={:0.2f}, Precision (no stroke)={:0.2f}\\nRecall (stroke)={:0.2f}, Recall (no stroke)={:0.2f}\\nF1 Score (stroke)={:0.2f}, F1 Score (no stroke)={:0.2f} \".format(accuracy,precision_stroke, precision, recall_stroke, recall, f1_score_stroke, f1_score)\n",
    "\n",
    "#Make the seaborn heatmap\n",
    "sns.heatmap(confusion_matrix, annot = labels, fmt = '', xticklabels = tick_labels, yticklabels = tick_labels)\n",
    "plt.xlabel(stats_text, fontsize = 14)\n",
    "plt.title(\"Gaussian Naive Bayes model\", fontsize = 14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SMOTE from imbalanced learn in order to create a balanced class dataset with synthetic samples\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "nbclf_smote = GaussianNB().fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for original test data but with model fitting after SMOTE synthetic data creation\n",
    "predictions = nbclf_smote.predict(X_test)\n",
    "sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix to see correct and incorrect predictions for original test data with SMOTE\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute precision, recall F1-score and support for original test data with SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SMOTE does not improve performance of our model. It only slightly improves recall; all other scores decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
